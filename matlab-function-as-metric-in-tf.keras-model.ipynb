{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matlab code in your tf.keras.Model!\n",
    "\n",
    "{Missing: Lead paragraph. Short and snappy intro. Two sentences.}\n",
    "\n",
    "{Missing: A beautiful image}\n",
    "\n",
    "As part of my Master's thesis at the [University of Bergen](https://www.uib.no/en/math) I am currently investigating deep learning super-resolution models applied to satellite images. Specifically I am adapting one of the best performing models, [ESRGAN](https://paperswithcode.com/paper/esrgan-enhanced-super-resolution-generative) to pairs of multispectral LR and panchromatic HR images. While everything Super-Resolution is Super-Fascinating the topic of this post is actually something completely different, namely how to implement matlab functions as metrics in your `tf.keras` models. Why would you need this? Well, in my case I really wanted to measure image quality with the [Ma et al.](https://www.sciencedirect.com/science/article/pii/S107731421630203X) metric and this metric is to my knowledge only available as [matlab code](https://github.com/chaoma99/sr-metric). I also wanted to evaluate the `Ma` score as training progressed, just like any other Keras metric. Translating the Matlab code to Python was out of scope for my thesis so I had to find another way.\n",
    "\n",
    "Before we jump into the actual code, a quick recap on [*eager execution*](https://www.tensorflow.org/guide/eager) and *graph execution* in `tf.keras` might be needed. The main thing to keep in mind is that if you opt for eager execution then calling Matlab functions through the `matlab.engine` API is as straight-forward as calling any other Python function. While eager execution is enabled by deafult since TensorFlow 2.0 it is **not** enabled by default in `tf.keras.Model` objects. While eager execution can be enabled in the `tf.keras.Model.compile()` method with the `run_eagerly` argument [it is not given that you should do this](https://towardsdatascience.com/eager-execution-vs-graph-execution-which-is-better-38162ea4dbf6). Eager execution is great for experimentation and debugging, but graph execution is usually much faster, uses less GPU memory and allows for easy parallelization. Can we still call Matlab functions from \"within\" static computational graphs? With the `tf.py_function()` we can!\n",
    "\n",
    "This blogpost is structured like a notebook. I will take you through two different examples of how to implement a Matlab function as a `tf.keras` metric. The first example is a straight forwards implementation, while in the second we are subclassing the `tf.keras.Model` class and customizing our `train_step()` and `test_step()` methods. Throughout the notebook we will be using the [MATLAB Engine API for Python](https://se.mathworks.com/help/matlab/matlab-engine-for-python.html) API to communicate with Matlab. As such it is a prerequisite to have Matlab installed on your computer. The version numbers for packages are printed in the first code-block below. The code was tested on Windows 10, but should be compatible with other platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and config parameters\n",
    "\n",
    "Let's start by importing the necessary libraries and define some config parameters that will be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 3.7.9\n",
      "numpy version: 1.18.5\n",
      "tensorflow version: 2.3.1\n",
      "matlab version: R2019a\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import matlab.engine\n",
    "import platform\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Library version numbers\n",
    "print('python version:', platform.python_version())\n",
    "print('numpy version:', np.__version__)\n",
    "print('tensorflow version:', tf.__version__)\n",
    "print('matlab version: R2019a')\n",
    "\n",
    "# Path to the directory with the matlab function of interest\n",
    "MATLAB_METRIC_DIR = 'matlab/'\n",
    "\n",
    "# Parameters used when defining the model\n",
    "IMAGE_H, IMAGE_W = 28, 28\n",
    "IMAGE_CHANNELS = 1\n",
    "N_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing MNIST\n",
    "\n",
    "We need to some data to train on in order to see if our matlab function is working. You are probably familiar with the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) handwritten digit dataset. It is all about predicting digits 0-9 from grayscale (one channel) 28x28 images of handwritten digits. We also need to do some basic preprocessing of the dataset. Images need to be [scaled](https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35) and converted to `float32` while labels need to be [one-hot-encoded](https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_images: (60000, 28, 28) <class 'numpy.uint8'> min: 0 max: 255\n",
      "train_set_labels: (60000,) <class 'numpy.uint8'> min: 0 max: 9\n",
      "Preprocessing...\n",
      "Preprocessing...\n",
      "train_set_images: (60000, 28, 28) <class 'numpy.float32'> min: 0.0 max: 1.0\n",
      "train_set_labels: (60000, 10) <class 'numpy.float32'> min: 0.0 max: 1.0\n",
      "\n",
      "Inspecting the first image and label pair:\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = data.load_data()\n",
    "\n",
    "print('train_set_images:', train_images.shape, type(train_images[0,0,0]), \n",
    "      'min:', np.min(train_images), 'max:', np.max(train_images))\n",
    "print('train_set_labels:', train_labels.shape,  type(train_labels[0]), \n",
    "      'min:', np.min(train_labels), 'max:', np.max(train_labels))\n",
    "\n",
    "def preprocess_mnist(images, labels):\n",
    "    print('Preprocessing...')\n",
    "    #One-hot-encoding of response variables 0-9\n",
    "    labels = tf.keras.utils.to_categorical(labels)\n",
    "    \n",
    "    # Rescaling: uint8(0,255) -> float32(0.0,1.0)\n",
    "    images = tf.image.convert_image_dtype(images, tf.float32).numpy()\n",
    "    return images, labels\n",
    "\n",
    "train_images, train_labels = preprocess_mnist(train_images, train_labels)\n",
    "test_images, test_labels = preprocess_mnist(test_images, test_labels)\n",
    "\n",
    "print('train_set_images:', train_images.shape, type(train_images[0,0,0]), \n",
    "      'min:', np.min(train_images), 'max:', np.max(train_images))\n",
    "print('train_set_labels:', train_labels.shape,  type(train_labels[0,0]), \n",
    "      'min:', np.min(train_labels), 'max:', np.max(train_labels))\n",
    "\n",
    "print('\\nInspecting the first image and label pair:')\n",
    "plt.imshow(train_images[0], cmap='gray')\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple convolutional model\n",
    "\n",
    "We also need a `tf.keras` model to train. Let us just build a simple [convolutional model](https://towardsdatascience.com/convolutional-neural-network-17fb77e76c05) that accepts 28x28x1 images and predicts a vector of length 10.\n",
    "\n",
    "*Note: If you wonder why the actual model instantiation is done outside of the function this is because we will later reuse the layer configuration, but not the actual `tf.keras.Model` object, when we subclass the `tf.keras.Model` class.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 24, 24, 16)        416       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 20, 8)         3208      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 4)         804       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 2)         202       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                2890      \n",
      "=================================================================\n",
      "Total params: 7,520\n",
      "Trainable params: 7,520\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def simple_conv_model():\n",
    "    input_layer = tf.keras.Input(shape=(IMAGE_H, IMAGE_W, IMAGE_CHANNELS))\n",
    "    x = tf.keras.layers.Conv2D(16, 5, activation=\"relu\")(input_layer)\n",
    "    x = tf.keras.layers.Conv2D(8, 5, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Conv2D(4, 5, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Conv2D(2, 5, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    output_layer = tf.keras.layers.Dense(N_CLASSES, activation='softmax')(x)\n",
    "    return input_layer, output_layer\n",
    "\n",
    "input_layer, output_layer = simple_conv_model()\n",
    "model = tf.keras.Model(input_layer, output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting matlab.engine\n",
    "\n",
    "Time to fire up the Matlab Engine! If your [install](https://se.mathworks.com/help/matlab/matlab_external/install-the-matlab-engine-for-python.html) went well this should be a breeze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting matlab.engine ...\n",
      "matlab.engine started\n"
     ]
    }
   ],
   "source": [
    "def start_matlab():\n",
    "    print('Starting matlab.engine ...')\n",
    "    eng = matlab.engine.start_matlab()\n",
    "    \n",
    "    # Changing the current working directory of the matlab engine\n",
    "    # to the directory containing our matlab function .m file\n",
    "    eng.cd(str(pathlib.Path(MATLAB_METRIC_DIR).resolve()))\n",
    "    \n",
    "    # Verifying that the engine has started\n",
    "    if isinstance(eng, matlab.engine.matlabengine.MatlabEngine):\n",
    "        print('matlab.engine started')\n",
    "    return eng\n",
    "matlab_engine = start_matlab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Matlab function\n",
    "\n",
    "In order to compare with existing `tf.keras.metrics` our Matlab function is a basic accuracy function. It uses the Matlab internal [confusion](https://se.mathworks.com/help/deeplearning/ref/confusion.html) function. This is probably not the most efficient way of implementing an accuracy function, but it was quick to code."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "function [acc] = accuracy(y_true,y_pred)\n",
    "%ACCURACY Returns the fraction of samples correctly classified\n",
    "c = confusion(y_true, y_pred);\n",
    "acc = 1-c;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Python/Matlab/TensorFlow metrics functions\n",
    "\n",
    "There are many ways to code the functions wrapping the `matlab.engine` call to our `accuracy.m` matlab function. This is only one way to do it. We create two functions. `matlab_accuracy` is a pure `tf` function that accepts and returns a tensors. The only job of this function is to use a [tf.py_function](https://www.tensorflow.org/api_docs/python/tf/py_function) to call on the Python `py_matlab_accuracy` function. `py_function` allows us to \"step into\" *eager execution*, do some work, and return back into *graph execution*. In our case \"do some work\" means call on our matlab function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def py_matlab_accuracy(y_true, y_pred):\n",
    "    # Check that the graph is executing eagerly. It should.\n",
    "    assert tf.executing_eagerly()\n",
    "    \n",
    "    # Since we are running eagerly we can convert tensor to np.ndarray\n",
    "    y_true, y_pred = y_true.numpy(), y_pred.numpy()\n",
    "    \n",
    "    # accuracy.m requires transpose matrices\n",
    "    y_true, y_pred = np.transpose(y_true), np.transpose(y_pred)\n",
    "    \n",
    "    # converting ndarrays to matlab double matrices\n",
    "    y_true, y_pred = matlab.double(y_true.tolist()), matlab.double(y_pred.tolist())\n",
    "    \n",
    "    # calling the matlab function\n",
    "    metric = matlab_engine.accuracy(y_true, y_pred)\n",
    "    \n",
    "    # returning the metric as a tensor\n",
    "    return tf.constant(metric, tf.float32)\n",
    "\n",
    "def matlab_accuracy(y_true, y_pred):\n",
    "    # Notice how we need to define output data type tf.float32\n",
    "    matlab_metric = tf.py_function(py_matlab_accuracy, [y_true, y_pred], [tf.float32])\n",
    "    return matlab_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, fit and inspect our Matlab metric\n",
    "\n",
    "It is time to test our implementation. This is where we get rewarded by the `tf.keras.Model` objects simple API. As can be seen in the code below all that now is required is to pass our `matlab_accuracy` function as a metric in the `compile` method.\n",
    "\n",
    "Comparing `accuracy` with `matlab_accuracy` we find that their values are, except for minor rounding differences, equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.8268 - accuracy: 0.7320 - matlab_accuracy: 0.7320 - val_loss: 0.4116 - val_accuracy: 0.8746 - val_matlab_accuracy: 0.8749\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 0.3620 - accuracy: 0.8918 - matlab_accuracy: 0.8918 - val_loss: 0.2915 - val_accuracy: 0.9104 - val_matlab_accuracy: 0.9105\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.2778 - accuracy: 0.9162 - matlab_accuracy: 0.9162 - val_loss: 0.2342 - val_accuracy: 0.9290 - val_matlab_accuracy: 0.9290\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.2270 - accuracy: 0.9338 - matlab_accuracy: 0.9338 - val_loss: 0.1837 - val_accuracy: 0.9452 - val_matlab_accuracy: 0.9455\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 10s 52ms/step - loss: 0.2076 - accuracy: 0.9376 - matlab_accuracy: 0.9376 - val_loss: 0.1947 - val_accuracy: 0.9418 - val_matlab_accuracy: 0.9418\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy', matlab_accuracy])\n",
    "\n",
    "EPOCHS = 5\n",
    "history = model.fit(x=train_images, y=train_labels, \n",
    "          batch_size=64, epochs = EPOCHS, steps_per_epoch = 200,\n",
    "          validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if you want full control of the metric calculation?\n",
    "\n",
    "Looping back to my Super-Resolution problem in the introduction I wanted to implement [Ma et al.](https://www.sciencedirect.com/science/article/pii/S107731421630203X)'s Matlab image quality metric, but the calculation of this metric is computationally expensive and due to time limitations I decided I could only afford to run it on the validation images. Such a setup is, to my knowledge, not possible to configure directly in the `tf.keras` API. \n",
    "\n",
    "If we still want the benefits of working with `tf.keras.Model` objects what we can do is to write a subclass with customized  `train_step` and `test_step` methods so that the Matlab metric is only calculated when validating/testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # Inheriting everything enables normal use of CustomModel\n",
    "        super(CustomModel, self).__init__(*args, **kwargs)\n",
    "    \n",
    "        # Our matlab function and \n",
    "        self.matlab_accuracy_fn = None\n",
    "        self.matlab_accuracy_mean = None\n",
    "        \n",
    "    def compile(self, *args, **kwargs):\n",
    "        # Inheriting everything enables normal use of compile method\n",
    "        super(CustomModel, self).compile(*args, **kwargs)\n",
    "        \n",
    "        # compile() assigns our matlab_accuracy function to the CustomModel object\n",
    "        self.matlab_accuracy_fn = matlab_accuracy\n",
    "        \n",
    "        # Object needed to properly calulate and report a metric\n",
    "        # within the tf.keras framework:\n",
    "        self.matlab_accuracy_mean = tf.keras.metrics.Mean(name='matlab_accuracy')\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        super(CustomModel, self).train_step(data)\n",
    "        \n",
    "        # Only tweak to train_step is to avoid reporting matlab_accuracy\n",
    "        # by popping it from the metrics dict before return\n",
    "        metrics_to_report = {m.name: m.result() for m in self.metrics}\n",
    "        metrics_to_report.pop(self.matlab_accuracy_mean.name)\n",
    "        return metrics_to_report\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # No inheritance\n",
    "        x, y = data\n",
    "        y_pred = self(x, training=False)\n",
    "        \n",
    "        # compiled_loss, compiled_metrics allows adding more\n",
    "        # losses and metrics in the compile method.\n",
    "        self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        \n",
    "        # Checks that the graph is static. It should be\n",
    "        assert not tf.executing_eagerly() \n",
    "    \n",
    "        # The actual matlab call\n",
    "        matlab_accuracy_value = self.matlab_accuracy_fn(y, y_pred)\n",
    "        \n",
    "        # Checks that the graph is static. It should be\n",
    "        assert not tf.executing_eagerly()\n",
    "        \n",
    "        # Update the metric object\n",
    "        self.matlab_accuracy_mean.update_state(matlab_accuracy_value)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        metrics = super().metrics\n",
    "        metrics.append(self.matlab_accuracy_mean)\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build, compile, fit and inspect our Matlab metric\n",
    "\n",
    "That should be it. Now we need to build a new model, `custom_model` with the same convolutional design as the `model` model, but with the difference being that we instantiate it as a `CustomModel` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.8165 - accuracy: 0.7229 - val_loss: 0.2766 - val_accuracy: 0.9133 - val_matlab_accuracy: 0.9134\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.2491 - accuracy: 0.9202 - val_loss: 0.2025 - val_accuracy: 0.9384 - val_matlab_accuracy: 0.9387\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.2015 - accuracy: 0.9384 - val_loss: 0.1694 - val_accuracy: 0.9482 - val_matlab_accuracy: 0.9484\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 6s 31ms/step - loss: 0.1812 - accuracy: 0.9432 - val_loss: 0.1562 - val_accuracy: 0.9525 - val_matlab_accuracy: 0.9527\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.1615 - accuracy: 0.9514 - val_loss: 0.1278 - val_accuracy: 0.9634 - val_matlab_accuracy: 0.9636\n"
     ]
    }
   ],
   "source": [
    "# Building a CustomModel model\n",
    "input_layer, output_layer = simple_conv_model()\n",
    "custom_model = CustomModel(input_layer, output_layer)\n",
    "\n",
    "# Compiling. Note that matlab_accuracy is not passed as a metric.\n",
    "custom_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "EPOCHS = 5\n",
    "history = custom_model.fit(x=train_images, y=train_labels, \n",
    "          batch_size=64, epochs = EPOCHS, steps_per_epoch = 200,\n",
    "          validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Make a note on computation time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
